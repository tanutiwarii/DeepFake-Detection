ğŸ“Œ Overview

This repository contains the implementation of a Deepfake Detection model leveraging Convolutional Neural Networks (CNNs), Vision Transformers (ViT), ResNet, and Logistic Regression. The goal is to detect manipulated facial images and videos using deep learning and traditional machine learning techniques.

ğŸ” Problem Statement

Deepfakes pose a significant threat to digital security, misinformation, and privacy. This project aims to develop a robust model that can efficiently differentiate between real and fake images/videos.

ğŸ—ï¸ Model Architectures

The project explores multiple architectures:

CNN: Captures spatial features and local patterns.
ResNet: Handles deeper networks using residual connections to prevent vanishing gradients.
Vision Transformer (ViT): Extracts global dependencies using self-attention mechanisms for effective feature representation.
Logistic Regression: Acts as a simple baseline model for classification.
ğŸ“‚ Dataset

We have used publicly available deepfake datasets such as:

FaceForensics++
Celeb-DF
âš™ï¸ Methodology

Data Preprocessing
âœ”ï¸ Face detection and alignment
âœ”ï¸ Data augmentation for better generalization

Model Training
âœ”ï¸ Implemented CNN, ResNet, ViT, and Logistic Regression architectures
âœ”ï¸ Used Transfer Learning for better performance
âœ”ï¸ Fine-tuned hyperparameters for optimization
![output](https://github.com/user-attachments/assets/72550fed-c50e-4453-9ad2-368e343ccd67)

Evaluation Metrics
âœ”ï¸ Accuracy
âœ”ï¸ Precision, Recall, and F1-Score
âœ”ï¸ AUC-ROC Curve

ğŸ› ï¸ Technologies Used

Python, TensorFlow/Keras, PyTorch
OpenCV for image processing
Matplotlib & Seaborn for visualization
Scikit-learn for evaluation metrics & Logistic Regression
ğŸš€ Results

Our best-performing model achieved:
âœ… CNN: 86.19% Accuracy
âœ… ResNet: 92.68% Accuracy
âœ… ViT: 98.11% Accuracy
âœ… Logistic Regression: 51.05% Accuracy (Baseline Model)

ğŸ“œ Research Paper

The research paper detailing this work is available in the repository under DeepFake_Final.pdf.
